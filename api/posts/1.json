{"total":27,"pageSize":12,"pageCount":3,"data":[{"title":"决策树","uid":"c8a7e9308e269c0b57685bf049081ac1","slug":"决策树","date":"2023-02-28T08:34:59.000Z","updated":"2023-02-28T08:34:59.648Z","comments":true,"path":"api/articles/决策树.json","cover":null,"text":" ","link":"","photos":[],"count_time":{"symbolsCount":2,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},{"title":"DenseNet","uid":"806a34f762f55e51b9922352f8456268","slug":"DenseNet","date":"2023-02-27T11:23:20.000Z","updated":"2023-03-09T05:24:25.158Z","comments":true,"path":"api/articles/DenseNet.json","cover":[],"text":"DenseNet Introduction 从ResNet到DenseNet 在ResNet中，我们通过的方式来训练模型 而从这个式子中，我们可以很容易的联想的Taylor公式 而DenseNet就是在ResNet的基础上，对该公式进行了进一步的展开 ResNet将f(x)分为了...","link":"","photos":[],"count_time":{"symbolsCount":"1k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"},{"name":"经典模型","slug":"AI学习/经典模型","count":5,"path":"api/categories/AI学习/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"},{"name":"经典模型","slug":"经典模型","count":6,"path":"api/tags/经典模型.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},{"title":"ResNet","uid":"8f025f73c51b2b366e2e8ff8dcf261a1","slug":"ResNet","date":"2023-02-27T11:23:08.000Z","updated":"2023-03-09T05:15:30.776Z","comments":true,"path":"api/articles/ResNet.json","cover":[],"text":"ResNet 论文原址 李沐读论文——ResNet ResNet博客详解 代码 pytorch官方代码 嵌套函数 假设有一类特定的神经网络架构F，它包括学习速率和其他超参数设置。 对于所有，存在一些参数集（例如权重和偏置），这些参数可以通过在合适的数据集上进行训练而获得 现在假设...","link":"","photos":[],"count_time":{"symbolsCount":"2.4k","symbolsTime":"2 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"},{"name":"经典模型","slug":"AI学习/经典模型","count":5,"path":"api/categories/AI学习/经典模型.json"},{"name":"论文精读","slug":"AI学习/经典模型/论文精读","count":1,"path":"api/categories/AI学习/经典模型/论文精读.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"},{"name":"论文精读","slug":"论文精读","count":3,"path":"api/tags/论文精读.json"},{"name":"经典模型","slug":"经典模型","count":6,"path":"api/tags/经典模型.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},{"title":"批量规范化","uid":"232f9f51309688e33bd70bd8c0ccce09","slug":"批量规范化","date":"2023-02-27T11:23:00.000Z","updated":"2023-02-27T11:23:00.242Z","comments":true,"path":"api/articles/批量规范化.json","cover":null,"text":" ","link":"","photos":[],"count_time":{"symbolsCount":2,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"最大公因数GCD","uid":"9d8d702581fafe91f0e84d17245c7b9e","slug":"最大公因数GCD","date":"2023-02-25T14:29:59.174Z","updated":"2022-01-12T11:25:28.992Z","comments":true,"path":"api/articles/最大公因数GCD.json","cover":null,"text":"最大公因数GCD 原理 利用了欧几里得算法，即辗转相除法 核心等式——gcd(a,b) = gcd(b,a mod b) 证明 a可以表示成a = kb + r（a，b，k，r皆为正整数) 假设d是a,b的一个公约数，记作d|a,d|b) 即a和b都可以被d整除。 而r = a ...","link":"","photos":[],"count_time":{"symbolsCount":888,"symbolsTime":"1 mins."},"categories":[{"name":"算法","slug":"算法","count":11,"path":"api/categories/算法.json"}],"tags":[{"name":"算法","slug":"算法","count":11,"path":"api/tags/算法.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"GoogLeNet","uid":"f466839ba23e30f0626022c248cd73f5","slug":"GoogLeNet","date":"2023-02-24T12:58:30.000Z","updated":"2023-02-27T11:21:45.654Z","comments":true,"path":"api/articles/GoogLeNet.json","cover":[],"text":"GoogLeNet Introduction GoogLeNet吸收了NiN中串联网络的思想，并在此基础上做了改进 这篇论文的一个重点是解决了什么样大小的卷积核最合适的问题 本文的一个观点是，有时使用不同大小的卷积核组合是有利的 模型结构——Inception块 在GoogLeN...","link":"","photos":[],"count_time":{"symbolsCount":"3.2k","symbolsTime":"3 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"},{"name":"经典模型","slug":"AI学习/经典模型","count":5,"path":"api/categories/AI学习/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"},{"name":"经典模型","slug":"经典模型","count":6,"path":"api/tags/经典模型.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"NiN","uid":"c8663499333ced86e35b7c271cd82e06","slug":"NiN","date":"2023-02-24T11:41:11.000Z","updated":"2023-02-24T12:55:45.211Z","comments":true,"path":"api/articles/NiN.json","cover":[],"text":"NiN——网络中的网络 Inroduction LeNet、AlexNet和VGG都有一个共同的设计模式： 通过一系列的卷积层与汇聚层来提取空间结构特征，然后通过全连接层对特征的表征进行处理 AlexNet和VGG对LeNet的提升主要在于如何扩大和加深这两个模块 而这之中就发现...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"},{"name":"经典模型","slug":"AI学习/经典模型","count":5,"path":"api/categories/AI学习/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"},{"name":"经典模型","slug":"经典模型","count":6,"path":"api/tags/经典模型.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"VGG","uid":"e488f86556a876ba1fc98ee3101d0802","slug":"VGG","date":"2023-02-24T08:01:55.000Z","updated":"2023-02-24T11:16:14.159Z","comments":true,"path":"api/articles/VGG.json","cover":[],"text":"VGG VGG论文 d2l Introdution AlexNet的成果，证明了CNN在图像分类领域的强大性能，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络 与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象 研究人员...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"},{"name":"经典模型","slug":"AI学习/经典模型","count":5,"path":"api/categories/AI学习/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"},{"name":"经典模型","slug":"经典模型","count":6,"path":"api/tags/经典模型.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"如何精读文章","uid":"2c4c0bf1dd06ffaa7e2ce0054928cf5c","slug":"如何精读文章","date":"2023-02-21T06:16:10.000Z","updated":"2023-02-26T14:44:04.262Z","comments":true,"path":"api/articles/如何精读文章.json","cover":null,"text":"如何精读文章 这篇文章主要参考了李沐老师的讲解，以及我本科导师的推荐方法，外加上本人平日阅读时的感受 仅代表个人见解，欢迎交流讨论 阅读方法——三步读法 李沐老师介绍的三步读法大致按照以下几个步骤 导读 在导读，也就是第一次阅读时，我们主要关注文章的标题、摘要和结论 标题，也就是...","link":"","photos":[],"count_time":{"symbolsCount":494,"symbolsTime":"1 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":1,"path":"api/categories/论文精读.json"}],"tags":[{"name":"论文精读","slug":"论文精读","count":3,"path":"api/tags/论文精读.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"AlexNet","uid":"c6ff40f5693e190d69588e9c4620b737","slug":"AlexNet","date":"2023-02-20T12:55:00.000Z","updated":"2023-02-24T09:17:21.833Z","comments":true,"path":"api/articles/AlexNet.json","cover":[],"text":"AlexNet 论文原址 跟李沐读论文——AlexNet 三步读法 1. 导览——标题、摘要、结论 标题 ImageNet Classification with Deep Convolutional Neural Networks 从中可以感受到几个重点： 数据集：ImageN...","link":"","photos":[],"count_time":{"symbolsCount":"2.4k","symbolsTime":"2 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"},{"name":"论文精读","slug":"AI学习/论文精读","count":1,"path":"api/categories/AI学习/论文精读.json"},{"name":"经典模型","slug":"AI学习/论文精读/经典模型","count":1,"path":"api/categories/AI学习/论文精读/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"},{"name":"论文精读","slug":"论文精读","count":3,"path":"api/tags/论文精读.json"},{"name":"经典模型","slug":"经典模型","count":6,"path":"api/tags/经典模型.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"LeNet","uid":"139386a48ee9ff8eae54fecf132447a0","slug":"LeNet","date":"2023-02-20T10:33:27.000Z","updated":"2023-02-20T12:45:01.242Z","comments":true,"path":"api/articles/LeNet.json","cover":[],"text":"LeNet Introduction 这是世界上最早发布的卷积神经网络之一，由AT&amp;T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名） 目的是识别图像 MNIST 中的手写数字 当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的...","link":"","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"信息论","uid":"a0a717998dbf88c81be122d0bce3bca3","slug":"信息论","date":"2023-02-18T10:32:18.000Z","updated":"2023-02-18T10:44:30.881Z","comments":true,"path":"api/articles/信息论.json","cover":null,"text":"Information Theory MLAPP 2.8 Preface 信息论(Information Theory)：应用数学的一个分支，涉及用紧凑的方法来表示数据（如数据压缩和编码），以及具有鲁棒性的储存和传输数据。在机器学习中，信息论常常应用于连续型变量 信息论的基本想法...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}]}