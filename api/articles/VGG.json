{"title":"VGG","uid":"e488f86556a876ba1fc98ee3101d0802","slug":"VGG","date":"2023-02-24T08:01:55.000Z","updated":"2023-02-24T11:16:14.159Z","comments":true,"path":"api/articles/VGG.json","keywords":null,"cover":[],"content":"<h1 id=\"vgg\">VGG</h1>\r\n<p><a href=\"https://arxiv.org/abs/1409.1556\">VGG论文</a></p>\r\n<p><a href=\"https://zh.d2l.ai/chapter_convolutional-modern/vgg.html\">d2l</a></p>\r\n<h2 id=\"introdution\">Introdution</h2>\r\n<p>AlexNet的成果，证明了CNN在图像分类领域的强大性能，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络</p>\r\n<p>与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象</p>\r\n<p>研究人员开始从单个神经元的角度思考问题，发展到整个层，现在又转向块，重复层的模式</p>\r\n<p>而使用块的想法首先出现在牛津大学的视觉几何组（visual geometry\r\ngroup）的VGG网络中</p>\r\n<p>通过使用循环和子程序，可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构</p>\r\n<h2 id=\"模型结构vgg块\">模型结构——VGG块</h2>\r\n<p>从之前AlexNet论文中所提出的CNN模型中，我们可以总结出CNN模型的的基本组成为：\r\n- 带填充和步幅来调整和保证分辨率的卷积层 - 非线性激活函数 - 池化层</p>\r\n<p>而VGG块与上面所总结的类似，由一系列卷积层，相应的激活函数和一个池化层所组成</p>\r\n<p>在VGG原论文中，作者使用了带有<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.554ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2222.4 687\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container></span>卷积核、填充为1（保持高度和宽度）的卷积层，和带有<span class=\"math inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.507ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 666\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container></span>汇聚窗口、步幅为2（每个块后的分辨率减半）的最大汇聚层</p>\r\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import torch\nfrom torch import nn\n\ndef vgg_block(nums_conv, in_channels, out_channels):\n# nums_conv 卷积层数量\n# in_channels 输入通道数\n# out_channels 输出通道数\n\tlayers = []\n\tfor _ in range(nums_conv):\n\t\tlayers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n\t\tlayers.append(nn.ReLU())\n\t\tin_channels = out_channels\n\tlayers.append(nn.MaxPool2d(kernel_size=1))\n\treturn nn.Sequential(*layers)</code></pre>\r\n<h2 id=\"模型结构vgg网络\">模型结构——VGG网络</h2>\r\n<p><img src=\"https://zh.d2l.ai/_images/vgg.svg\"></p>\r\n<p>与AlexNet和LeNet一样，VGG仍然是以卷积块和全连接块两部分组成，其主要区别在于，VGG拥有着较为灵活的VGG块</p>\r\n<p>通过调整每个VGG块的超参数，就可以定制不同的VGG模型，下面以VGG-11为例</p>\r\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">conv_arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n# vgg-11的vgg块超参数</code></pre>\r\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">def vgg(conv_arch):\n\tconv_blks = []\n\tin_channels = 1\n\tfor (nums_conv, out_channels) in conv_arch:\n\t\tconv_blks.append(vgg_block(nums_conv, in_channels, out_channels))\n\t\tin_channels = out_channels\n\t# 卷积部分\n\treturn nn.Sequential(\n\t\t*conv_blks, nn.Flatten(),\n\t\tnn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n\t\tnn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n\t\tnn.Linear(4096, 10)\n\t\t# 这里的10由数据集决定\n\t)</code></pre>\r\n","text":"VGG VGG论文 d2l Introdution AlexNet的成果，证明了CNN在图像分类领域的强大性能，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络 与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象 研究人员...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":8,"path":"api/categories/AI学习.json"},{"name":"经典模型","slug":"AI学习/经典模型","count":2,"path":"api/categories/AI学习/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":8,"path":"api/tags/AI学习.json"},{"name":"经典模型","slug":"经典模型","count":3,"path":"api/tags/经典模型.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#vgg\"><span class=\"toc-text\">VGG</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#introdution\"><span class=\"toc-text\">Introdution</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84vgg%E5%9D%97\"><span class=\"toc-text\">模型结构——VGG块</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84vgg%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">模型结构——VGG网络</span></a></li></ol></li></ol>","author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"NiN","uid":"c8663499333ced86e35b7c271cd82e06","slug":"NiN","date":"2023-02-24T11:41:11.000Z","updated":"2023-02-24T12:55:45.211Z","comments":true,"path":"api/articles/NiN.json","keywords":null,"cover":[],"text":"NiN——网络中的网络 Inroduction LeNet、AlexNet和VGG都有一个共同的设计模式： 通过一系列的卷积层与汇聚层来提取空间结构特征，然后通过全连接层对特征的表征进行处理 AlexNet和VGG对LeNet的提升主要在于如何扩大和加深这两个模块 而这之中就发现...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":8,"path":"api/categories/AI学习.json"},{"name":"经典模型","slug":"AI学习/经典模型","count":2,"path":"api/categories/AI学习/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":8,"path":"api/tags/AI学习.json"},{"name":"经典模型","slug":"经典模型","count":3,"path":"api/tags/经典模型.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"如何精读文章","uid":"2c4c0bf1dd06ffaa7e2ce0054928cf5c","slug":"如何精读文章","date":"2023-02-21T06:16:10.000Z","updated":"2023-02-26T14:44:04.262Z","comments":true,"path":"api/articles/如何精读文章.json","keywords":null,"cover":null,"text":"如何精读文章 这篇文章主要参考了李沐老师的讲解，以及我本科导师的推荐方法，外加上本人平日阅读时的感受 仅代表个人见解，欢迎交流讨论 阅读方法——三步读法 李沐老师介绍的三步读法大致按照以下几个步骤 导读 在导读，也就是第一次阅读时，我们主要关注文章的标题、摘要和结论 标题，也就是...","link":"","photos":[],"count_time":{"symbolsCount":494,"symbolsTime":"1 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":1,"path":"api/categories/论文精读.json"}],"tags":[{"name":"论文精读","slug":"论文精读","count":2,"path":"api/tags/论文精读.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}