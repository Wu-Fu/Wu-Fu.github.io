{"title":"AlexNet","uid":"c6ff40f5693e190d69588e9c4620b737","slug":"AlexNet","date":"2023-02-20T12:55:00.000Z","updated":"2023-02-24T09:17:21.833Z","comments":true,"path":"api/articles/AlexNet.json","keywords":null,"cover":[],"content":"<h1 id=\"alexnet\">AlexNet</h1>\r\n<p><a href=\"https://dl.acm.org/doi/abs/10.1145/3065386\">论文原址</a></p>\r\n<p><a href=\"https://www.bilibili.com/video/BV1ih411J7Kz/?spm_id_from=333.999.0.0&amp;vd_source=0010e78b7a63f02a4bea165f8571cf1c\">跟李沐读论文——AlexNet</a></p>\r\n<h2 id=\"三步读法\">三步读法</h2>\r\n<h3 id=\"导览标题摘要结论\">1. 导览——标题、摘要、结论</h3>\r\n<h4 id=\"标题\">标题</h4>\r\n<p>ImageNet Classification with Deep Convolutional Neural Networks</p>\r\n<p>从中可以感受到几个重点：</p>\r\n<p>数据集：ImageNet</p>\r\n<p>当时最大的数据集，也是DNN与传统机器学习相比，发挥不佳的数据集，是当时DNN在CV领域研究的重难点</p>\r\n<p>创新点：Deep Convolutional Nerual Networks</p>\r\n<p>虽然在如今的视角下，CNN已经在DNN领域得到了非常广泛的应用，但在当时的研究背景下，CNN是一个非常新鲜且陌生的概念，因此可以被认为是本文的创新点</p>\r\n<h4 id=\"摘要\">摘要</h4>\r\n<p>在摘要中，这篇文章主要分为以下几个部分：</p>\r\n<ul>\r\n<li>总起：以LSVRC竞赛为例，展示了模型在ImageNet上的效果非常好</li>\r\n<li>介绍：大致介绍了模型的结构和参数数量，以及当时少见的神经元数量</li>\r\n<li>训练：表示本文采取GPU训练（在当时已经逐渐流行的一种训练方式）</li>\r\n<li>技巧：介绍了本文为减少过拟合所采取的技巧——dropout</li>\r\n</ul>\r\n<p>从上可看出，本文的摘要突出了一件事——<strong>我们网络的效果好</strong></p>\r\n<p>（虽然本文是非常经典的论文，但这篇文章所采取的摘要结构不建议作为参考）</p>\r\n<h4 id=\"结论\">结论</h4>\r\n<p>非常罕见，本篇文章中并没有Consequence部分，故本部分以Discussion作为代替</p>\r\n<p>总结：对本篇文章中CNN所取得的成果进行总结与肯定，并且对未来进行展望</p>\r\n<p>消融：总结了实验中，减少CNN模型深度所带来的影响，得出结论：CNN模型与模型深度具有非常相关的联系</p>\r\n<p>展望：回顾实验，表示了本文在有监督学习下的效果很好，而无需另外的无监督学习的预处理</p>\r\n<p>这段话也使得，DNN领域一时间将研究的重点转向了有监督学习之中</p>\r\n<p>展望：如果未来的计算资源越来越强大，则可以得到更好的效果</p>\r\n<p>不足：承认当下的技术与人类能力还存在较大差距，对未来的工作进行期待</p>\r\n<h4 id=\"直观感受与简单总结\">直观感受与简单总结</h4>\r\n<p>这篇文章，作为CNN领域的开山之作，是一篇非常具有开创性的文章</p>\r\n<p>重新回到2012年的视角去看待，这篇文章最吸引人的地方在于：\r\n在CV领域提出了了一个全新的且超越过去所有技术的新概念——CNN</p>\r\n<p>而在摘要与结论中也能感受到AlexNet所关心的重点——模型结构、效果和采取的技巧Dropout</p>\r\n<h3 id=\"通读\">2. 通读</h3>\r\n<p><a href=\"https://readpaper.com/pdf-annotate/note?pdfId=551651939155394560&amp;noteId=1663429425570600960\">ReadPaper——我的论文笔记</a></p>\r\n<h3 id=\"精读\">3. 精读</h3>\r\n<h4 id=\"数据集\">数据集</h4>\r\n<p>在数据集方面，AlexNet摒弃了以往CV领域所使用的特征流水线技术，开始转而使用带标签的数据集</p>\r\n<p>从而带火了端到端(End to\r\nEnd，指训练与使用的输入与输出相对应)在CV领域的广泛应用</p>\r\n<p>此处特另外展现一下过去的特征流水线： -\r\n获取一个有趣的数据集。在早期，收集这些数据集需要昂贵的传感器（在当时最先进的图像也就100万像素）\r\n- 根据光学、几何学、其他知识以及偶然的发现，手工对特征数据集进行预处理 -\r\n通过标准的特征提取算法，如SIFT（尺度不变特征变换） (Lowe,\r\n2004)和SURF（加速鲁棒特征） (Bay et al.,\r\n2006)或其他手动调整的流水线来输入数据 -\r\n将提取的特征送入最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器</p>\r\n<h4 id=\"模型详解\">模型详解</h4>\r\n<p><img src=\"https://img-blog.csdn.net/20180202191501974?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZGNybWc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\"></p>\r\n<p>每一个框表示每一层输入输出数据的大小，小方块表示卷积核</p>\r\n<p>从上图可以看出，输入的高宽逐渐变小，深度，即通道数逐渐增加</p>\r\n<p>这表示着模型中逐步压缩图片数据的一个过程，而通道数可以理解为每个通道数表示一种模式的提取</p>\r\n<p>经过这个过程，一个样本就经由逐层的加工最终转化为一个特征向量，而在决策空间中，我们用这个特征向量代表对于的样本，因此我们可以对这个向量来进行其他的处理，这也是DNN的精髓所在</p>\r\n<h4 id=\"减少过拟合\">减少过拟合</h4>\r\n<p>数据增强</p>\r\n<p>PCA正则化</p>\r\n<p>Dropout算法</p>\r\n<h2 id=\"代码\">代码</h2>\r\n<figure>\r\n<img src=\"https://zh.d2l.ai/_images/alexnet.svg\" alt=\"AlexNet和LeNet的比较\">\r\n<figcaption aria-hidden=\"true\">AlexNet和LeNet的比较</figcaption>\r\n</figure>\r\n<p>LeNet和AlexNet模型结构的比较</p>\r\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import torch\nfrom torch import nn\n\nAlexNet = nn.Sequential(\n\t# 输入经过预处理\n\tnn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n\tnn.MaxPool2d(kernel_size=3, stride=2),\n\t# 使用一个11*11的大窗口，外加96个输出通道来快速提取图像特征\n\tnn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n\tnn.MaxPool2d(kernel_size=3, stride=2),\n\t# 切换成小窗口，通过填充来保证输入输出大小一致\n\tnn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n\tnn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n\tnn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n\tnn.MaxPool2d(kernel_size=3, stride=2),\n\t# 使用了3个卷积层和较小的窗口\n\tnn.flatten(),\n\tnn.Linear(4096, 4096), nn.ReLU(),\n\tnn.Dropout(p=0.5),\n\tnn.Linear(4096, 4096), nn.ReLU(),\n\tnn.Dropout(p=0.5),\n\tnn.Linear(4096, 10)\n\t# 最后的这个10由训练集决定\n)</code></pre>\r\n","text":"AlexNet 论文原址 跟李沐读论文——AlexNet 三步读法 1. 导览——标题、摘要、结论 标题 ImageNet Classification with Deep Convolutional Neural Networks 从中可以感受到几个重点： 数据集：ImageN...","link":"","photos":[],"count_time":{"symbolsCount":"2.4k","symbolsTime":"2 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"},{"name":"论文精读","slug":"AI学习/论文精读","count":1,"path":"api/categories/AI学习/论文精读.json"},{"name":"经典模型","slug":"AI学习/论文精读/经典模型","count":1,"path":"api/categories/AI学习/论文精读/经典模型.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"},{"name":"论文精读","slug":"论文精读","count":3,"path":"api/tags/论文精读.json"},{"name":"经典模型","slug":"经典模型","count":6,"path":"api/tags/经典模型.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#alexnet\"><span class=\"toc-text\">AlexNet</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%89%E6%AD%A5%E8%AF%BB%E6%B3%95\"><span class=\"toc-text\">三步读法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AF%BC%E8%A7%88%E6%A0%87%E9%A2%98%E6%91%98%E8%A6%81%E7%BB%93%E8%AE%BA\"><span class=\"toc-text\">1. 导览——标题、摘要、结论</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%A0%87%E9%A2%98\"><span class=\"toc-text\">标题</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%91%98%E8%A6%81\"><span class=\"toc-text\">摘要</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BB%93%E8%AE%BA\"><span class=\"toc-text\">结论</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%9B%B4%E8%A7%82%E6%84%9F%E5%8F%97%E4%B8%8E%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">直观感受与简单总结</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%80%9A%E8%AF%BB\"><span class=\"toc-text\">2. 通读</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%B2%BE%E8%AF%BB\"><span class=\"toc-text\">3. 精读</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">数据集</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3\"><span class=\"toc-text\">模型详解</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%87%8F%E5%B0%91%E8%BF%87%E6%8B%9F%E5%90%88\"><span class=\"toc-text\">减少过拟合</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">代码</span></a></li></ol></li></ol>","author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"如何精读文章","uid":"2c4c0bf1dd06ffaa7e2ce0054928cf5c","slug":"如何精读文章","date":"2023-02-21T06:16:10.000Z","updated":"2023-02-26T14:44:04.262Z","comments":true,"path":"api/articles/如何精读文章.json","keywords":null,"cover":null,"text":"如何精读文章 这篇文章主要参考了李沐老师的讲解，以及我本科导师的推荐方法，外加上本人平日阅读时的感受 仅代表个人见解，欢迎交流讨论 阅读方法——三步读法 李沐老师介绍的三步读法大致按照以下几个步骤 导读 在导读，也就是第一次阅读时，我们主要关注文章的标题、摘要和结论 标题，也就是...","link":"","photos":[],"count_time":{"symbolsCount":494,"symbolsTime":"1 mins."},"categories":[{"name":"论文精读","slug":"论文精读","count":1,"path":"api/categories/论文精读.json"}],"tags":[{"name":"论文精读","slug":"论文精读","count":3,"path":"api/tags/论文精读.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"LeNet","uid":"139386a48ee9ff8eae54fecf132447a0","slug":"LeNet","date":"2023-02-20T10:33:27.000Z","updated":"2023-02-20T12:45:01.242Z","comments":true,"path":"api/articles/LeNet.json","keywords":null,"cover":[],"text":"LeNet Introduction 这是世界上最早发布的卷积神经网络之一，由AT&amp;T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名） 目的是识别图像 MNIST 中的手写数字 当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的...","link":"","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/categories/AI学习.json"}],"tags":[{"name":"AI学习","slug":"AI学习","count":11,"path":"api/tags/AI学习.json"}],"author":{"name":"碔砆","slug":"blog-author","avatar":"https://s1.ax1x.com/2023/02/20/pSXmfmj.jpg","link":"/","description":"BUPT AI专业大二学生","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}